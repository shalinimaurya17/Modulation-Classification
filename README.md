Over the past five years, there has been a focus on creating deep learning architectures for radio modulation recognition. Many of these architectures are either convolutional neural networks, recurrent neural networks, or the combination of those and contain over a million trainable parameters. This paper focuses on a reduction of the parameters in the networks while maintaining comparable accuracy. We introduce an architectures Residual Networks (RESNET) . The results presented in this paper are comparable to or even outperform architectures with up to 20 times more parameters. Significant parameter reduction presented in this paper is more suitable for later model deployment on an embedded platform with limited memory size and computational power. We further discuss other needed steps before implementing the architectures on an embedded platform other than the model size reduction at the end of the paper.
